"""
Traditional image similarity utilities for environments where AI embeddings are
not allowed.

This module provides a light-weight feature extractor plus an in-memory index
that can be used to compare images using classic computer-vision descriptors
only (color histograms, gradient orientation histograms, and coarse spatial
intensity grids).  The resulting vectors can be stored locally or uploaded to
Qdrant just like any other embedding.
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence

import numpy as np
from loguru import logger
from PIL import Image

try:  # Pillow 9+ moved resampling enums under Image.Resampling
    RESAMPLE_LANCZOS = Image.Resampling.LANCZOS  # type: ignore[attr-defined]
except AttributeError:  # pragma: no cover
    RESAMPLE_LANCZOS = Image.LANCZOS  # type: ignore[attr-defined]

# Reuse the same extensions as the CLI helper.
SUPPORTED_IMAGE_EXTENSIONS = {".png", ".jpg", ".jpeg", ".webp"}


@dataclass
class IndexedImage:
    """Container storing an indexed image and its feature vector."""

    path: Path
    vector: np.ndarray
    metadata: Dict[str, str]


class TraditionalFeatureExtractor:
    """
    Compute deterministic, low-dimensional descriptors for an image using only
    traditional computer vision techniques.
    """

    def __init__(
        self,
        color_bins: int = 16,
        gradient_bins: int = 16,
        spatial_size: int = 32,
        max_side: int = 256,
    ) -> None:
        if color_bins <= 0 or gradient_bins <= 0:
            raise ValueError("color_bins and gradient_bins must be > 0")
        if spatial_size <= 0:
            raise ValueError("spatial_size must be > 0")

        self.color_bins = color_bins
        self.gradient_bins = gradient_bins
        self.spatial_size = spatial_size
        self.max_side = max_side

    def extract(self, image_path: Path) -> np.ndarray:
        """
        Extract the combined feature vector for the provided image.
        """
        if not image_path.exists():
            raise FileNotFoundError(image_path)

        with Image.open(image_path) as image:
            image = image.convert("RGB")
            image.thumbnail((self.max_side, self.max_side), RESAMPLE_LANCZOS)
            rgb_array = np.asarray(image, dtype=np.float32)

        color_hist = self._color_histogram(rgb_array)
        gradient_hist = self._gradient_histogram(rgb_array)
        spatial = self._spatial_grid(rgb_array)

        feature = np.concatenate([color_hist, gradient_hist, spatial]).astype(np.float32)
        norm = float(np.linalg.norm(feature))
        if norm == 0:
            return feature
        return feature / norm

    def feature_size(self) -> int:
        """Total number of dimensions generated by this extractor."""
        color = self.color_bins * 3
        gradient = self.gradient_bins
        spatial = self.spatial_size * self.spatial_size
        return color + gradient + spatial

    def _color_histogram(self, rgb_array: np.ndarray) -> np.ndarray:
        hist_list: List[np.ndarray] = []
        for channel in range(3):
            channel_data = rgb_array[:, :, channel]
            hist, _ = np.histogram(
                channel_data,
                bins=self.color_bins,
                range=(0, 255),
            )
            hist_list.append(hist.astype(np.float32))
        hist_vector = np.concatenate(hist_list)
        total = float(hist_vector.sum())
        if total > 0:
            hist_vector /= total
        return hist_vector

    def _gradient_histogram(self, rgb_array: np.ndarray) -> np.ndarray:
        gray = np.mean(rgb_array, axis=2)
        gy, gx = np.gradient(gray)
        magnitude = np.sqrt(gx ** 2 + gy ** 2)
        orientation = (np.arctan2(gy, gx) + np.pi) / (2 * np.pi)  # 0..1
        hist, _ = np.histogram(
            orientation,
            bins=self.gradient_bins,
            range=(0.0, 1.0),
            weights=magnitude,
        )
        hist = hist.astype(np.float32)
        total = float(hist.sum())
        if total > 0:
            hist /= total
        return hist

    def _spatial_grid(self, rgb_array: np.ndarray) -> np.ndarray:
        gray = np.mean(rgb_array, axis=2)
        gray_image = Image.fromarray(gray.astype(np.uint8))
        gray_image = gray_image.resize(
            (self.spatial_size, self.spatial_size),
            RESAMPLE_LANCZOS,
        )
        grid = np.asarray(gray_image, dtype=np.float32).flatten() / 255.0
        return grid


class TraditionalImageIndex:
    """
    Light-weight in-memory index for traditional feature vectors.
    """

    def __init__(self, extractor: Optional[TraditionalFeatureExtractor] = None) -> None:
        self.extractor = extractor or TraditionalFeatureExtractor()
        self.records: List[IndexedImage] = []
        self._matrix: Optional[np.ndarray] = None

    def add_image(self, image_path: Path, metadata: Optional[Dict[str, str]] = None) -> None:
        vector = self.extractor.extract(image_path)
        record = IndexedImage(
            path=image_path.resolve(),
            vector=vector,
            metadata=metadata or {},
        )
        self.records.append(record)
        self._matrix = None  # invalidate cache

    def add_images(self, image_paths: Sequence[Path]) -> int:
        count = 0
        for image_path in image_paths:
            suffix = image_path.suffix.lower()
            if suffix not in SUPPORTED_IMAGE_EXTENSIONS:
                logger.debug("Skipping unsupported file: %s", image_path)
                continue
            try:
                self.add_image(image_path)
                count += 1
            except Exception as exc:  # pylint: disable=broad-except
                logger.warning("Failed to index %s: %s", image_path, exc)
        return count

    def finalize(self) -> None:
        if not self.records:
            raise ValueError("No images have been indexed yet.")
        self._matrix = np.vstack([record.vector for record in self.records]).astype(np.float32)

    def search(
        self,
        query_image: Path,
        top_k: int = 5,
    ) -> List[Dict[str, object]]:
        if not self.records:
            raise ValueError("Cannot search without indexed images.")
        if self._matrix is None:
            self.finalize()

        query_vec = self.extractor.extract(query_image)
        scores = self._matrix @ query_vec
        best_indices = np.argsort(scores)[::-1][:top_k]

        results: List[Dict[str, object]] = []
        for idx in best_indices:
            record = self.records[int(idx)]
            results.append(
                {
                    "image_path": str(record.path),
                    "score": float(scores[idx]),
                    "metadata": record.metadata,
                }
            )
        return results

    def save(self, target: Path) -> None:
        if self._matrix is None:
            self.finalize()
        payload = {
            "vectors": self._matrix,
            "paths": np.array([str(r.path) for r in self.records], dtype=np.unicode_),
            "metadata": np.array([json.dumps(r.metadata) for r in self.records], dtype=np.unicode_),
        }
        np.savez_compressed(target, **payload)
        logger.info("Saved traditional index with %d images to %s", len(self.records), target)

    @classmethod
    def load(
        cls,
        source: Path,
        extractor: Optional[TraditionalFeatureExtractor] = None,
    ) -> "TraditionalImageIndex":
        if not source.exists():
            raise FileNotFoundError(source)
        data = np.load(source, allow_pickle=False)
        vectors = data["vectors"].astype(np.float32)
        paths = data["paths"]
        metadata_raw = data["metadata"]

        index = cls(extractor=extractor)
        for vector, path_str, meta_str in zip(vectors, paths, metadata_raw):
            metadata = json.loads(meta_str)
            index.records.append(
                IndexedImage(
                    path=Path(str(path_str)),
                    vector=vector,
                    metadata=metadata,
                )
            )
        index._matrix = vectors
        logger.info("Loaded traditional index with %d images from %s", len(index.records), source)
        return index

    def as_payload(self) -> List[Dict[str, object]]:
        """
        Export the indexed vectors as payload dictionaries that can be ingested
        into Qdrant or any other vector database.
        """
        payload: List[Dict[str, object]] = []
        for record in self.records:
            payload.append(
                {
                    "vector": record.vector.tolist(),
                    "metadata": {
                        **record.metadata,
                        "image_path": str(record.path),
                        "feature_type": "traditional",
                    },
                }
            )
        return payload


